---
title: 'scopingwork.Rmd: Asses/describe JG fundraising pages/donations; scoping sponsorship design'
author: "David Reinstein,  Tobias Jolly, Riener(?)"
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output:
  html_document:
   css: /Library/Frameworks/R.framework/Versions/3.5/Resources/library/summarytools/includes/stylesheets/summarytools.css
   toc: true
   toc_float: true
   number_sections: true
   code_folding: hide
   theme: flatly
---

<!--
#(?add 'parameters' to the above?)
#params: #remove_excess_files: TRUE #runcodebooks: FALSE
-->

This file is run (in main.R) with command  ` rmarkdown::render('R/scopingwork.Rmd') `
Code folding in markdown; view HTML in browser

# Introduction and goals {#introduction}

We are running an expGeriment on peer/social influences on donations in an online fundraising setting. The aim of this study is to assess the impact large (small) additional donation(s) to a fundraiser’s page can have on subsequent donations to that page, with a particular focus on fundraisers for effective charities (expanding on the GiveWell definition). We will select a universe of pages in the category we are interested in, select treatment and control pages and add a single anonymous donation of a particular size (or two sizes, power/funds permitting) to the treatment pages very soon after they are founded. Our experiment and project is further described at <https://osf.io/6m4n2/>, which also embeds this file via Github.

## Design parameters: {#parameters}

We are scoping out a design that is feasible as well as statistically powerful. The 'parameters' we can play with are:

*(Todo: move to 'declaredesign' formats and tools, code these formally.)*

`length` (days) of trial (also `startdate`)

`frequency` (how often we check the pages, at what `checktimes`)

`inclusion` criteria for charities ('how effective, by what measure?')

Also, for future consideration: SEED_SIZE(s), SEED_TIMING

Considering additional arm: `message`

Design targets ('diagnosands'): POWER to detect effect of SIZE given TEST (chosen estimator). Also relevance of environment, and scaleability/replicability.

Constraints: COST, (EFFORT time), ethics, participant awareness (avoid them realising donations come from experimenters)

## Key questions for scoping our pilot, to answer here {#key_questions}

(@) *Q_Sample_size*: If we check with FREQUENCY (considering INCLUSION criteria), how many useable pages do we get (mean, dispersion) as a function of LENGTH? --> implications for LENGTH, FREQUENCY, INCLUSION

- And how does this vary seasonally (--> STARTDATE)

(@) *Q_Longevity*: How long do we need to follow a page ... until we get 'most' (or most of the variance in) total donations? --> (LENGTH)
 
(@) *Q_Early_contributions*: At CHECKTIMES, what do the profile of 'early contributions' look like (number, average, dispersion in this)? --> our design (esp SIZE) and COST

(@) *Q_Inclusion*: Which ('effective') charities (INCLUSION) can predictably yield enough pages to contribute to statistical inference?

(@) *Q_Exploratory* are there any highly predictable patterns or exotic pages that suggest non-INCLUSION

## Data extracts to use here

Below, we gather the following data sets for further power calculations and treatment assignment ('randomisation') design.

`UCFdd`: Historical (completed) fundraisers and donations, with data on observables at CHECKTIME and at end 
- To fit a model of 'predicted donations' to use for treatment assignment design, and to run power calculations on this

`UCFdd_fd`: As above, but summarised at the level of 1 observation per fundraising page, with background data 

# File and code setup, define functions {#setup}

**Runs**

`baseopt_jg.R`:  basic options, definitions, abbreviations for functions

`combine_available_data.R`: Reads in fundraiser and donation data as pulled into folder `donations_folder` and `fundraising_folder`. Coding, merging, aggregating etc.  

`scopingfunctions.R`: helpful functions to use later 

```{r setupxx, include=TRUE, echo=FALSE, results='hide', cache=FALSE, warning=FALSE, message=FALSE, tidy=TRUE}

knitr::opts_chunk$set(echo = TRUE, results = 'asis')

options(scipen=100) #'penalizes' using scientific notation

library(pacman)
p_load(dplyr,magrittr,purrr,tidyverse,tidyr,broom,janitor,glue,dataMaid,glue,readr, lubridate,summarytools,gtools,knitr,pastecs,here,kableExtra,dfSummary) 

here <- here::here

source(here("baseopt_jg.R")) #basic options, definitions, abbreviations for functions

source(here("combine_available_data.R")) #check - many parsing failures

source(here("scopingfunctions.R")) #tabylstuff, dotplot_func, boxplot_func, geom_mean, sidebyside, huxoptions

sumnumopt <- setSummaries(numeric= c("centralValue" ,"quartiles", "minMax","countMissing"))

st_options("round.digits",3)

```

<!--
Include all objects from just_giving_data_pull as well as merged data.
Note: found a way to bring in data (or code?) from other data pull using .gitmodules 
-->

# Setup and background {#background}

Donation and fundraiser data pulled from JustGiving using (fundraising_data_pull R code)[https://github.com/TWJolly/fundraising_data_pull]

## Universe {#universe}

All (live?) pages founded from first to last data pull; (hard-code: 2018-4-14 to 15 May 2019) 

- `combine_available_data` merged all pulls in the folders: `r donations_folder` and `r fundraising_folder`

Note: this naturally oversamples 'surviving pages', i.e., those with longer expiry dates, with a stronger such bias the older the page. 

- Todo: Adjustments are needed to recover a representative sample;
   - crudest method: measure duration covering '80% of pages last longer than' remove all older than this
   - medium-crude: construct 'likelihood of survival this long' probabilities, randomly cull pages with these probabilities 
   - more sophisticated: constructs weights ('likelihood of surviving this long'), use in analysis

## Charities  - Criteria (hard-coded criteria 9 Jan 2019): {#charities}

* Highly-rated (eaf,give_well_top_2017,	give_well_standout_2017	life_you_can_save, ace,	givewell_other)	charities, plus charities  with an international poverty and global health (poor countries) focus.
    + (Mostly the latter) 
    + Airtable view [HERE](https://airtable.com/shr9BbBLUlGAYe4xa) 

* Only included those with a clearly identified ID on justgiving.

# Describe "historical" dataset {#describe_historical}

Below, we describe the data we downloaded from previous years to the present. 

*[Todo: descriptive variable names/labels]*

```{r print-summaries, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results='asis'}

print("Fundraisers")

print(dfSummary(Fundr_all),file=paste(outdir,"dfsumm_fundraising_page_data.html",sep="/")) #Better to use codebook for this?  

Fundr_all_x <- Fundr_all %>%
  select(TargetAmount,totalRaisedOnline,totalEstimatedGiftAid) %>%
  mutate_all(.funs = funs(as.numeric(.))) #Note, the variable names dissapear here with the pipe!

options(scipen = 8)
descr(Fundr_all_x, style = 'rmarkdown')

#Donations:
print(dfSummary(Don_all),file="dfsumm_donation_data.html") 

#Merged:
Fdd_non <- Fdd %>% select_if(is.numeric) %>% select(-matches("n_|cum")) 
print(dfSummary(Fdd_non), file="dfsumm_merged_fundraiser_donation_data.html")
  
#Which of the 'n_' or 'cum' variables cause the error 'Error in hist.default(data, breaks = breaks_x, plot = FALSE) :  some 'x' not counted; maybe 'breaks' do not span range of 'x' ??

Fundr_allOX <- Fundr_all %>% dplyr::filter(charity.name=="Oxfam") 
Fundr_allnotTW <- Fundr_all %>% dplyr::filter(eventName!="Trailwalker 2018") 

print(dfSummary(Fundr_allnotTW),file="dfsumm_merged_fundraiser_donation_data_Ox.html")

```

See summary files (generated in above code block and 'codebook' rmd's)

- [Fundraising pages original - dfsummary](dfsumm_fundraising_page_data.html)
- [Donation pages - dfsummary](dfsumm_donation_data.html)
- [Donation pages - codebook](codebook_Don_all.html)
- [Merged fundraising and donation pages](dfsumm_merged_fundraiser_donation_data.html) 
- [Fundraising pages codebook- aggregated donation vars - codebook](codebook_fdd_fd.html)
- [Oxfam other than Trailwalker: Merged fundraising and donation pages](dfsumm_merged_fundraiser_donation_data.html) 

# Inventory of effective/useable pages (historical) {#inventory}

Only some pages are useable for our experiment...

**Criteria for useability:** 

* Aforementioned charities 
* UK based
* Raised positive amount online
* (Excludes 'Trailwalker' - (this was split with a less effective charity)

```{r Filter-out-ineligible-pages-and-keep-key-variables, echo=TRUE, include=TRUE,results='hide'} 
#Number of elig pages generated X days after start, quantiles of this

#'useable' fundraisers (#I'd like to make the below filter a function, but I don't know how)
#filters pages that raised something online, UK-based, removes "Trailwalker"

UFundr <- Fundr_all %>%
  dplyr::filter(totalRaisedOnline>0, !grepl("Trailwalker",eventName),  CountryCode=="United Kingdom")  

UFdd <- Fdd %>%   dplyr::filter(totalRaisedOnline>0,!grepl("Trailwalker",eventName),  CountryCode=="United Kingdom")  

UFdd_fd <- Fdd_fd %>% dplyr::filter(sum_don>0,!grepl("Trailwalker",eventName),  CountryCode=="United Kingdom")  

#founded no more that 2 months before the start of our collection: #CreatedDate>ymd('2018-02-14')

print(dfSummary(UFundr),file="useable_fundraisers.html") 

#try(print(dfSummary(UFdd),file="useable_FDD.html"))
#Throws error: consult - https://stackoverflow.com/questions/40765655/r-histogram-range-error-some-x-not-counted-maybe-breaks-do-not-span-range 

useable_charity_pagecount <- sort(table(UFundr$charity),decreasing=TRUE) 

```

- [Useable fundraisers](useable_fundraisers.html)
- [Useable fundraisers with donations](useable_FDD.html)


```{r useable pagecounts table}

useable_charity_pagecount %>% kable(format="html", caption="Useable charity pagecounts, by charity") %>% kable_styling()

```


# Completed fundraisers and timeline of contributions {#completed_fundraisers}

In measuring 'predicted total donations' and doing our power calculations, we need to consider 'completed' (or nearly-completed) fundraising pages. We need to remove pages only recently launched.

**Plausibly 'completed' fundraisers defined as:**

- page is no longer active *or*
- time elapsed from founding/event $\rightarrow$  90\% of donation (amounts) are raised 95\% of the time. (Note: this should agree with the planned observation time for our experiment. )

**Add: histogram/table of 'share of funds raised' by 'week relative to start date/event date'**

**For expired pages, duration until 95\% of contributions were recieved. Estimate 90\% upper quantile on this**

UCFdd: Fundraisers with event date 25 weeks before today, or page is currently expired

- [completish_fundraisers.html](completish_fundraisers.html)

```{r complete-ish-fundraisers, echo=TRUE, include=TRUE,warning=FALSE}

UCFundr <- UFundr %>% filter(today()>ymd_hms(EventDate)+weeks(25)|today()>expiryDate)
UCFdd <- UFdd %>% filter(today()>ymd_hms(EventDate)+weeks(25)|today()>expiryDate)
UCFdd_fd <- UFdd_fd %>% filter(today()>ymd_hms(EventDate)+weeks(25)|today()>expiryDate)

```

<!--(Note: we moved codebook generation from here to elsewhere) -->

Summarizing these 'plausibly completed fundraisers':


``` {r summarise-complete-ish-fundraisers, echo=TRUE, include=TRUE,warning=FALSE}

dataMaid::summarize(UCFdd$dur_cd_95[UCFdd$donnum==1],  reportstyleOutput = TRUE, sumnumopt)   %>% kable(format="html", caption="Duration (in days, from creation date) until 95% of donations") %>% kable_styling()

dataMaid::summarize(UCFdd$cumsum_check[UCFdd$donnum==1], reportstyleOutput = TRUE, sumnumopt) %>% kable(format="html", caption="Sum of contributions at point of checking") %>% kable_styling()

#Sumstats on (sum of) contributions at point of checking
stat.desc(UCFdd$cumsum_check[UCFdd$donnum==1]) %>% kable(format="html", caption="Sum of contributions at point of checking: richer stats") %>% kable_styling()

print("why are there zeroes/missings here?")

#FIX: some zeroes in the above (97 pages); cumsum_check must be miscoded
# UCFdd %>% filter(cumsum_check==0,donnum==1) %>% View()

#todo (maybe): plot of 'average duration until x% of donations', with error bars/curve

#UCFdd %>% select(pageShortName,donationDate,CreatedDate,EventDate, donorLocalAmount,sum_donorLocalAmount,starts_with("cum"),starts_with("dur"),starts_with("n"),contains("don")) %>% arrange(pageShortName, donationDate)  %>% #group_by(pageShortName) %T>%  print("["(.,1:25,))  # %>% View() 

#Now a table/histogram of dur_cd_95 and dur_ed_95 by pageShortName 

print("'Time until 95% of funds raised' (days relative to created date)'")

(qtls_dur_cd_95 <- quantile(UCFdd$dur_cd_95[UCFdd$donnum==1],  probs = seq(0, 1, 0.05),na.rm = TRUE))

###Todo: Improve format of this


```

If we check each day at 11am and 10pm the breakdown of “number of donations on new sites” we can expect to see (frequencies for 1, 2, 3, 4, donations etc):

`r table(UCFdd$n_don_check[UCFdd$donnum==1])`

*(Doublecheck the above; it doesn't seem plausible)*

*Data issues: totalRaisedOnline is sometimes above/below the cumulative sum of donorLocalAmount*

# New takeaways 

## Data collection duration

To get 95% of the contributions for a page we need to wait `r qtls_dur_cd_95[[11]]` days at median, `r qtls_dur_cd_95[[16]]` days for 75% of pages, `r qtls_dur_cd_95[[19]]` days for 90% of the pages and `r qtls_dur_cd_95[[20]]` days for 95% of the pages.

**Some (hard-coded) takeaways from above (previous update)**

---

Amounts raised including gift aid (older list, hardcoded)

- Overall: Mean £306, median £139, IQR 325, sd, 306 
- For potential completed: Mean £456, median 298, IQR 500, sd 473

Larger list (but only 1 download)
- For potential completed: mean £96.72, median 220, IQR 368, sd 843 
  
<br><br>


Considering "effective charity pages permitting gift-aid with at least 1 donation"

* How often are they started... how long to generate X pages?
* For which charities?
* How much do they raise in total (distribution, time profile...)
* What do the new pages look like if ine checks in at 10am and 6pm each day?
  + Average amounts donated
  + Distribution of last/next contribution
  
```{r Time-to-generate-X-useable-pages, echo=FALSE, include=TRUE}

#Distribution of 'time to generate X (?) useable pages' if we start on a random Monday... 
#or just model the arrival rate of pages: mean and sd of time until next page generated? but there may be lots of clustering

UFundr %>% tabyl(wk_created) 
UFundr %>% tabyl(mo_created) 
UFundr %>% tabyl(wday_created)
UFundr %>% tabyl(hr_created)

#hours on weekdays  
#dplyr::filter(UFundr$hr_created)  (Commented out because it yields a bug, no idea why)

#hours on weekends
#dplyr::filter(UFundr$hr_created)

UFundr %>% group_by(wday_created) %>%
  add_tally() %>%
   ungroup() %>%
ggplot(aes(wday_created,n)) +  geom_boxplot()

#... (Distribution of) Number of useable pages after X weeks (note, for now we have to fudge this because we don't know *when* the donations were made)

#Distribution of donations for virgin pages at (10am and) 6pm
#to do:
#- join Don_all to Fundr_all pages, code datefirstdon='date of first donation on page', filter  only donations made before 6pm on datefirstdon on a page
#summarize (average, quantiles, number per page, etc) these donations

#todo: summarize *total* number of donations made on a page

#... also examine: fundraisingTarget, CharityId or charity, EventId/eventName, eventDate, expiryDate
#Explore (todo) ...  plot by day of week, etc

```

<br>

Takeaways from above;   (HARDCODED-- fix to make these dynamic!)
- Some stretches of only 2 or 3 in a week! (UPDATE -- that was from the smaller list)
- at least 14 in each month

--> This would suggest we need a design that allows *power* with only, say 100 total pages; however, with the larger list of charities we can gain a sample of 300 in perhaps 2 months.
-- 29 Dec 2018 -- with much larger list I think we can do this in a matter of weeks; doublecheck!

Timings: pages created throughout week, but almost twice as much on weekdays (other than Friday, which is intermediate). Few before 7am, fairly constant throughout workday until 5pm,  further dropoff at 10pm.

This *includes* the broader list of charities, but *excludes* pages with no donations, and excludes trailwalker pages. As these things come in clumps I expect we cannot count on another Trailwalker type event until a year from now. So perhaps we have to plan for as few as 20 new pages per month.

Thus we may want to focus on a very efficient design, particularly in balancing treatment and control pages, hopefully working with Max Kasy (a Harvard-based global expert on this). [We may also consider *multiple* seeds on an individual page, but that may make things less clean]

I also took a quick look at amounts raised on pages likely to be ‘finished’ (“completish_fundraisers” dataset).

Amounts raised including gift aid: Mean £456, median 298, IQR 500, sd 473
- Larger list: mean £96.72, median 220, IQR 368, sd 843 

To me this is sort of good news, as it suggests our seed of roughly  £40 might be more than  a drop-in-the-bucket

With the SMALLer list: So realistically, I am guessing that, unless we wait for the next Trailwalker or something similar, we might need to plan a design for something like a 6-month trial, anticipating 100-300 total pages.

At a cost of perhaps £1600-£4800 if we are splitting three ways between ‘double first donations’, ‘half first donations’ and ‘no seed’… (But this is very rough,  loads more calculations need doing, including my looking into the ‘first donations on such pages’, and doing some power calcs )

Larger list: we can count on about 30 pages per week or about 140 per month (the above numbers probably understate, as  from the earlier weeks the may have already expired thus I don’t see them)

 $\rightarrow$  can get our desired (300) sample size in about 2 months, at cost (with proposed 3-way split) perhaps [recheck with donation data] £5000

<br>

**(Cf ?Smith ?Payne et al)**

Fundraising	page mean (median) has	21 (14)	donations, raises £566 (£245).

Mean 21 donations, mean (median)  donation £24 (18 by page, £27 (20) by donation (?),

> individuals	fundraising	for	smaller	charities	(annual	incomes	<	£100K)	tend	to	raise	more	money	than	 individuals	fundraising	for	larger	charities

Individual-led fundraisers raise more on average than mass events

> Pages	with	a	target	raise	 significantly	more	than	pages	without	(+	£122).

> donors	give	less	once	the	target	has	been	reached	(an	average	of	£2	- £3 less).	

They seem to be able to link facebook/demographics!

...Sample: 416,313	fundraisers who	were	active	JustGiving	users	at	the	time	of	an	online	 survey that	ran	from	October	2010	– April	2011.	


# Power calculations {#power_calcs}

1. Simple? 

2. Ad hoc (Reinstein adapts Barrios), using prediction.Rmd quantiles; but this is not robust to TE heterogeneity 

3.  Kasy method?

- Prepare concise data set (csv?)
- Choose baseline covariates
- Estimator: Difference of means or Bayes
- Prior:  Squared exponential or Linear?
- Re-randomization draws (default=1000)
- Expected R-sq (default=0.7)

Stratify on 'discrete strata'

Conservative: difference in means without controls or interactions

More reasonable, fully general: Make estimator in Power calc regression with strata dummies and interactions with treatment, usual Robust standard errors 

But Kasy's technique makes inference difficult (frequentist not Bayesian) 

**Guidance/code:**

- Simple <https://egap.org/content/power-analysis-simulations-r>

- with 'paramtest' package: <https://cran.r-project.org/web/packages/paramtest/vignettes/Simulating-Power.html> (Note: not used because this is not geared towards using an existing data set)

```{r power-simulations}

#partly from https://stats.stackexchange.com/questions/37796/calculating-necessary-sample-size-using-bootstrap

power_data <- function(ds, reps, yvar, N, tshare=0.5, linTE=0, propTE=0,alpha=0.05) {
  #todo -- add argument 'testname'
  #N sample size being considered,
  #tshare is share allocated to treatment 
  #lin and prop are  linear or proportional treatment effects
  
  #Prelims for tidy eval
    yvar <-  enquo(yvar) #takes the argument and makes it into a 'quosure'... like quoting it, so dplyr commands can use it 
    yvar_name <-  quo_name(yvar) #quotes this argument in a way such that we can use it as a  *name*
    #testname <- enquo(testname)
    
  #Do the following simulation  'reps' number of times #purr::map is what Toby uses
    results  <- sapply(1:reps, function(r) {
  
    #Sample size N from data for each iteration
      exp_sample <- sample_n(ds, size=N, replace=TRUE) #WHY is it duplicating columns??
        
    #"Selection of control and treatment group: random assignment"; todo-- adapt to blocked-random designs etc.
        exp_sample <- exp_sample %>%
          mutate(
            d_t = row_number() <= (n()*tshare) #assign treatment dummy to first t-share of n rows
            ) %>% #"Add treatment effects to treatgroup"
             mutate(!! yvar_name :=  ifelse(
               d_t == "TRUE", !! yvar*(1+propTE)+ linTE, !!yvar)) %>%
                mutate(yv = !! yvar) %>% #reassign variable because I couldn't figure out how to get the unquoted argument to work in tests below  
            dplyr::select(yv, d_t) 
        
    #Do test
        test <- exp_sample %>% 
          do(tidy(
          wilcox.test(yv ~ d_t, data=., paired=FALSE))) #todo: adjust to make the test and its parameters function arguments
          #swapping in wilcox.test above works too
        test$p.value
    })
    sum(results<alpha)/reps
}

```

## Power calculation (examples) using our data

### For total donations 

```{r power-simulation-implementations}

pwr_n400_L50_p15 <- power_data(ds=UCFdd_fd,reps=100,yvar=sum_don,N=400,tshare=0.5,linTE=50,propTE=0.15,alpha=0.05)
  
pwr_n400_L100 <- power_data(ds=UCFdd_fd,reps=100,yvar=sum_don,N=400,tshare=0.5,linTE=100,propTE=0,alpha=0.05)

pwr_n400_p20_ct <- power_data(ds=UCFdd_fd,reps=100,yvar=count_don,N=400,tshare=0.5,propTE=0.2,alpha=0.05)

pwr_n400_L3_ct <- power_data(ds=UCFdd_fd,reps=100,yvar=count_don,N=400,tshare=0.5,linTE=3,propTE=0,alpha=0.05)


```

## Power calculations above

With 400 observations and pure randomization, simple simulated power tests (for t-tests) ...
  
For 'total donation':

- £50 linear effect + 15\% proportional effect  $\rightarrow$ `r pwr_n400_L50_p15` power 

- £100 linear effect only $\rightarrow$ `r pwr_n400_L100` power 

&nbsp;

For 'count of donations': 

- 20\% proportional effect  $\rightarrow$ `r pwr_n400_p20_ct` power 
- 3 units linear effect only (i.e., leads to 3 additional donations) $\rightarrow$ `r pwr_n400_L3_ct` power 

Note: Ranksum tests yield greater power.

### For total donations considering desired sample size (need to retool)

```{r samp-size-power}

(pwr_n400_L100 <- power_data(ds=UCFdd_fd,reps=100,yvar=sum_don,N=1000, tshare=0.1, linTE=100, propTE=0, alpha=0.015))

```


### Do: for donations within the next X hours

### Todo (power simulation code)

- grid search version (by N, TE size, etc)
- Construct a version of this with some form of blocked randomisation (ideally by 'predicted total donation')
  - perhaps limiting the analysis to a certain set of pages

EVA -- how accurately can we predict
As a sanity check, do a standard power calculation
Log to deal wiht outliers