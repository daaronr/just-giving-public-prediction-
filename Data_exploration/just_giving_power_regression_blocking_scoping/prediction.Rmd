---
title: "Project: predict the success of a JustGiving fundraiser based on its initial/early observable features; Dr. David Reinstein for BEE3066"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
date: "`r format(Sys.time(), '%d %B, %Y')`"
---


# Just giving prediction - Data described briefly

Donation and fundraiser data pulled from JustGiving.com using (fundraising_data_pull R code)[https://github.com/TWJolly/fundraising_data_pull] created by Toby Jolly. Visit JustGiving.com to learn more.
\

Pulled: All (live) pages founded from first to last data pull; (hard-code: 2018-4-14 to 15 May 2019 or most recent update); only pages that are 'live' at the time of the pull are captured. 

\

Highly-rated 'effective and international' charities selected only, and only pages with 1+ contributions. 

\ 

## Data extracts to use here

`UCFdd`: Historical (completed) fundraisers and donations, with data on observables at CHECKTIME and at end

- (Check?) 1 obs per donation

- To fit a model of 'predicted donations' 

\

`UCFdd_fd`: As above byt 

- but summarised at the level of 1 observation per fundraising page, with background data 

- This is probably the key data frame to use

Other relevant datasets/frames/objects:
  
...

# Project goals (goal 1 is essential, 2-3 are optional)

1. Create the 'best predictive model' of how much a fundraising page (started on JustGiving 'highly effective international charities', i.e., from this extract) will raise 

- ... within its "reasonable life" (e.g., until the fundraiser is ended or until it is 95% likely that 90% of the funds that will be raised have already been raised.)

- Alternately, the amount it will raise in a certain reasonable duration (e.g., 'after six months')

The model should be based solely on variables (features) one can observe within 12 hours after the first donation is made on the page. (We created several such variables already ... Should we create a list of these?)

\

Try to minimise (out-of-sample or cross-validated) prediction error (with error measured using either a squared-deviation or an absolute-deviation metric).

\

- Other outcome variables (e.g., number of donations made)  or aspects of the outcome (e.g., the upper tail of amounts raised) are also of interest

\

2. Identify particular economically-interesting or practically-interesting predictors of total amounts raised. The impact of the timing, amounts, and messages left on the earliest contributions (those within 12 hours of the first contribution) are of particular interest. 

\

3. Measure and test whether the model form (or key parameters of the model) are significantly different among the targeted charities.

\

## A proposed plan

0. Download the data using an interface to the JG API (this has been done for you, but you can try to do a download yourself if you like)

1. Define and organize the set of variables (features) available at intervention (done for you, but you can augment it if you like)

- 'cleaning and imputation' may be important here where variables are missing or problematic (give a tool to help with this? ... the 'recipes' package perhaps. )

2. Define and calculate the outcome variables (total amount raised) (again, done for you unless you want to look at an additional)

The key outcome variable is `df$var`

- We may need to filter only those pages that are plausibly 'completed' (ended or most of funds likely to be raised)... note in particular the 'event date'

3. Split and set-aside training and test data

4. Model the outcome... I suggest using a shrinkage model, e.g.:

- A Lasso Regression using all features. The regularization/penalty parameter could be optimized for best fit. (Cross-fold).

- A Ridge Regression using all features. The regularization/penalty parameter could be optimized for best fit. (Cross-fold).

- An 'Elastic net' optimising over both the regularisation parameter and the parameter determining how much the L1 and L2 norms are weighted.

5. After all analysis has been done measure the prediction success of the model on the set-aside data. *Do not* re-fit the model after this, as it risks over-fitting. (Instructor: you may choose to create a set-aside dataset yourself to make this a fair contest (i.e., to 'gamify' it, to use the trendy term)]

# Further data description and links to codebooks



# Further code snippets and functions that may be helpful 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#source("../code/Recipes.R") #recipes prepare data for distinct models/analyses
```

```{r lists or vectors of variables, echo=FALSE}

# Baseline covariates
v_paget <- c(CreatedDate,hr_created, wday_created, mo_created, wk_created,EventDate,expiryDate) #variables of page  timing

v_page <- c(TargetAmount, activityId,activityType,charity,companyAppealId,EventId) #variables present at start of page... could add some constructed from parsing "title" and "Subtext"
#cleaning: "charity" should be checked against CharityId to make sure we didn't get the wrong one

#wtf is "score?"
#what's FundraiserRevenueStreamId?

v_early_don <- c() #variables referring to donations *prior* to the treatment; we need to create/extract these using the donations file 

v_treat <- c() #characteristics of the (simulated or actual treatment)
v_outcomes <- c(totalEstimatedGiftAidm, totalRaisedOffline, totalRaisedOnline) #Outcomes to model

```

# Links to relevant Economics papers

