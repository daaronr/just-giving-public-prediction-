---
title: "Project: predict the success of a JustGiving fundraiser based on its initial/early observable features; Dr. David Reinstein for BEE3066"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    code_folding: hide
    df_print: paged
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

Setup... combines data
```{r setup-chunk-add-here, cache=TRUE, warning=FALSE}

library(here)
#library(checkpoint) #to avoid differential processing from different package versions
library(pacman)
here <- here::here
p_load(dplyr,magrittr,purrr,tidyverse,tidyr,broom,janitor,here,glue,dataMaid,glue,readr, lubridate,summarytools,gtools,knitr,pastecs,data.table, kableExtra, recipes)  #citr, reporttools, experiment, estimatr,  kableExtra, ggsignif, glmnet, glmnetUtils, rsample,snakecase,zoo

library(codebook)
source(here("R","baseopt_jg.R")) #basic options, definitions, abbreviations for functions, folder path names


#put data together
source(here::here("R","combine_available_data.R"))
```


# Just giving prediction - Data described briefly

Donation and fundraiser data pulled from JustGiving.com using (fundraising_data_pull R code)[https://github.com/TWJolly/fundraising_data_pull] created by Toby Jolly. Visit JustGiving.com to learn more.
\

Pulled: All (live) pages founded from first to last data pull; (hard-code: 2018-4-14 to 15 May 2019 or most recent update); only pages that are 'live' at the time of the pull are captured. 

\

Highly-rated 'effective and international' charities selected only, and only pages with 1+ contributions. 

\ 

## Data extracts to use here

`uc_fdd`: Donations from UK-based pages in the above category, with information on the fundraisers these donations occurred on.

- One row per donation
- the 'uc_' rather than 'u_' prefix denotes that we have kept only fundraisers 'completed' 25+ weeks ago

\
`uc_fdd_fd`: UK based fundraising pages in the above category, with aggregated statistics on donations by fundraiser"

- This is probably the key data frame to use

Other relevant datasets/frames/objects:
  
...

# Project goals (goal 1 is essential, 2-3 are optional) {#goals}

1. Create the 'best predictive model' of how much a fundraising page (started on JustGiving 'highly effective international charities', i.e., from this extract) will raise 

The key outcome variable is `uc_fdd_fd$sum_don` (in the other data set a similar variable is coded as `u_fdd$totalRaisedOnline`)

\

- The aim here is to predict how much a fundraiser will raise within its "reasonable life" (e.g., until the fundraiser is ended or until it is 95% likely that 90% of the funds that will be raised have already been raised.)

- Alternately, the amount it will raise in a certain reasonable duration (e.g., 'after six months')

The model should be based solely on variables (features) one can observe within 12 hours after the first donation is made on the page. (We created several such variables already ... Should we create a list of these?)

\

Try to minimise (out-of-sample or cross-validated) prediction error (with error measured using either a squared-deviation or an absolute-deviation metric).

\

- Other outcome variables (e.g., number of donations made)  or aspects of the outcome (e.g., the upper tail of amounts raised) are also of interest

\

2. Identify particular economically-interesting or practically-interesting predictors of total amounts raised. The impact of the timing, amounts, and messages left on the earliest contributions (those within 12 hours of the first contribution) are of particular interest. 

\

3. Measure and test whether the model form (or key parameters of the model) are significantly different among the targeted charities.

\

## A proposed plan

0. Download the data using an interface to the JG API (this has been done for you, but you can try to do a download yourself if you like)

1. Define and organize the set of variables (features) available at intervention (done for you, but you can augment it if you like)

- 'cleaning and imputation' may be important here where variables are missing or problematic ( the 'recipes' package can help with this.)

2. Define and calculate the outcome variables (total amount raised) (again, done for you unless you want to look at an additional)

The key outcome variable is `uc_fdd_fd$sum_don` (in the other data set a similar variable is coded as `u_fdd$totalRaisedOnline`); see discussion to consider other variables. 

- We may need to filter only those pages that are plausibly 'completed' (ended or most of funds likely to be raised)... note in particular the 'event date' (again, this has been done in a simple way if you use the `uc_xxx` rather than the `u_xxx` versions of the frames; feel free to consider a more sophisticated trimming)

\



3. Split and set-aside training and test data

4. Model the outcome... I suggest using a shrinkage model, e.g.:

- A Lasso Regression using all features. The regularization/penalty parameter could be optimized for best fit. (Cross-fold).

- A Ridge Regression using all features. The regularization/penalty parameter could be optimized for best fit. (Cross-fold).

- An 'Elastic net' optimising over both the regularisation parameter and the parameter determining how much the L1 and L2 norms are weighted.

5. After all analysis has been done measure the prediction success of the model on the set-aside data. *Do not* re-fit the model after this, as it risks over-fitting. (Instructor: you may choose to create a set-aside dataset yourself to make this a fair contest (i.e., to 'gamify' it, to use the trendy term)]

# Description of variables in uc_fdd_fd

charity: The name of the charity which the fundraiser was set up for.
fundraising_target: The target set for the fundraiser to earn.
country_code: An indicator for the country in which the fundraiser was started. For the data selected for this prediction project, the only country is the United Kingdom.
total_estimated_gift_aid: The total amount of funding from gift aid that the fundraiser received.Gift aid is a tax based scheme enabling registered charities to reclaim tax on a donation made by a UK taxpayer, effectively increasing the amount of the donation. https://en.wikipedia.org/wiki/Gift_Aid
page_short_name: The shortened name of the fundraising page.
activity_id: An identifier number for the fundraising page.
event_id: An identifier number for the fundraising event.
activity_type: The type of fundraising event, for example a Charity Cycle.
event_date: The date on which the fundraising event occurred or will occur.
expiry_date: The date when fundraising ended, in this case all expiry dates are NA.
status: Whether the fundraiser was Active, Cancelled or Completed at the time in which the API pulled the data.
created_date: Date when the fundraiser was created.
wday_created: The day of the week on which the event was created.
hr_created: The hour of the day in which the fundraiser was created.
count_don: The number of donations.
med_don: The median donation of this fundraiser.
mn_don: The mean donation of this fundraiser.
dur_cdate: This is defined as being the interval between the created date and the variable donationDate.
dur_edate: This is defined as being the interval between the EventDate and the donationDate.

# Further data description and links to codebooks

See all html files in 'codebooks' folder, especially: 

- [codebook_u_fdd: donations, with page info](codebooks/codebook_u_fdd.html)

- [codebook_uc_fdd: donations, with page info, expired/event 25+ weeks ago](codebooks/codebook_uc_fdd.html)

- [codebook_u_fdd_fd: pages, with aggregated donation info](codebooks/codebook_u_fdd.html)

\

## Criterion for inclusion, continued

* Highly-rated (eaf,give_well_top_2017,	give_well_standout_2017	life_you_can_save, ace,	givewell_other)	charities, plus charities  with an international poverty and global health (poor countries) focus.
    + (Mostly the latter)
    + Airtable view [HERE](https://airtable.com/shr9BbBLUlGAYe4xa)

* Only included those with a clearly identified ID on justgiving.

## How 'plausibly completed' was defined


In measuring 'predicted total donations' we need to consider 'completed' (or nearly-completed) fundraising pages. We need to remove pages only recently launched.

For now the 'uc_' data frames keep a fundraiser where 
- event date more than 25 weeks ago 

- or expiry date passed

\

## More detail on this; Constructing a representative sample (advanced; undergraduates may skip this) {#timingsample}

**Plausibly 'completed' fundraisers should be defined as:**

- page is no longer active *or*
- time elapsed from founding/event $\rightarrow$  90\% of donation (amounts) are raised 95\% of the time. (Note: this should agree with the planned observation time for our experiment. )

**For expired pages, duration until 95\% of contributions were recieved. Estimate 90\% upper quantile on this**

Note: the sampling of 'live' pages on the site naturally oversamples 'surviving pages', i.e., those with longer expiry dates, with a stronger such bias the older the page.

- Adjustments are needed to recover a representative sample;
   - crudest method: measure duration covering '80% of pages last longer than' remove all older than this
   - medium-crude: construct 'likelihood of survival this long' probabilities, randomly cull pages with these probabilities
   - more sophisticated: constructs weights ('likelihood of surviving this long'), use in analysis

# Further code snippets and functions that may be helpful 



## Some key lists of outcome and prediction variables

... you can find more and construct transformations of these, of course

```{r lists or vectors of variables, echo=FALSE}

v_outcomes <- c("totalEstimatedGiftAidm", "totalRaisedOffline", "totalRaisedOnline") #Outcomes one should model, especially totalRaisedOnline -- from uc_fdd

v_outcomes_f <- c("sum_don", "count_don") #outcomes to model from fundraiser data set


# Baseline covariates
v_paget <- c("CreatedDate","hr_created", "wday_created", "mo_created", "wk_created", "EventDate", "expiryDate") #variables of page  timing


v_page <- c("TargetAmount", "activityId", "activityType", "charity", "companyAppealId", "EventId") #variables present at start of page... could add some constructed from parsing "title" and "Subtext"

v_early_don <- c() # to construct: variables referring to donations *prior* to the treatment; we need to create/extract these using the donations file 

# A fancy person could try to generate variables based on the messages used


```

### The 'recipe' package

... some sample code to start with if you want to try this package; it will need adjusting to choose the right variables and imputations, and code below may have bugs! 

```{r, eval=FALSE}

rec_fd_don <- recipe(sum_don ~ ., data = uc_fdd_fd) %>%
  step_meanimpute(all_numeric(), -all_outcomes())   %>%
  step_modeimpute(all_nominal()) %>% #mode eimputation because nearest neighbor crashes
  step_dummy(all_nominal(), -all_outcomes(), -id) # need a 'design matrix' 

fd_imputed <- prep(rec_fd_don, data = uc_fdd_fd ) %>%
  bake(new_data = uc_fdd_fd)

x <- model.matrix(sum_don ~., fd_imputed %>% dplyr::select(v_page, -id))[,-1]

y <- fd_imputed$sum_don

pp("todo: split training and testing data")

```

### Doing some modeling ... code needs to be adapted; and it may contain bugs!

```{r, eval=FALSE}

don_cv_glmnet <- cv.glmnet(x, y, alpha = 0.5, family = "gaussian") #play around with this; can you find the 'optimal' alpha... alpha=0 is ridge, alpha=1 is pure lasso?

# Fit the final model on  training data 

model <- glmnet(x, y, alpha = 0.5, family = "gaussian",
                lambda = don_cv_glmnet$lambda.min) 

# Make predictions on the test data (need to split that out)

x.test <- model.matrix(sum_don ~., fd_imputed %>% dplyr::select(everything(), -id))[,-1]
donation_predicted <- model %>% predict(newx = x.test)

sx_imputed_1_pred <- cbind(donation_predicted, fd_imputed) %>%
  dplyr::select(donation_predicted = s0, id)


```


## Data collection duration (an aside fun bit of code...)

```{r}
#Now a table/histogram of dur_cd_95 and dur_ed_95 by pageShortName

print("'Time until 95% of funds raised' (days relative to created date)'")

(qtls_dur_cd_95 <- quantile(u_fdd$dur_cd_95[u_fdd$donnum==1],  probs = seq(0, 1, 0.05),na.rm = TRUE))

```

```{r}

stat.desc(u_fdd$cumsum_check[u_fdd$donnum==1]) %>% kable(format="html", caption="Sum of contributions 12 hours after start point: richer stats") %>% kable_styling()

```


To get 95% of the contributions for a page we need to wait `r qtls_dur_cd_95[[11]]` days at median, `r qtls_dur_cd_95[[16]]` days for 75% of pages, `r qtls_dur_cd_95[[19]]` days for 90% of the pages and `r qtls_dur_cd_95[[20]]` days for 95% of the pages.

\


# Optional: remove extra data frames

Do you want to remove the extra data frames (used in construction). These may be useful for a more ambitious analysis; comment this out if you don't want to remove.

```{r}

rm(u_fdd,u_fdd_fd,u_fundr,u_fundr_all, don_all,  fdd_fd,fdd, uc_fundr) 
```


\



# Links to relevant Economics papers

Smith, Sarah, Frank Windmeijer, and Edmund Wright. "Peer effects in charitable giving: Evidence from the (running) field." The Economic Journal 125, no. 585 (2015): 1053-1071.

\

Payne, Abigail, Kimberley Scharf, and Sarah Smith. Online fundraising-the perfect ask?. No. 194. Competitive Advantage in the Global Economy (CAGE), 2014.
